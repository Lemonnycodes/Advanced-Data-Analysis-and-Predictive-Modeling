{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') \n",
        "       \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvy5-0Bxi_Uw",
        "outputId": "9e9a7f4f-c0e6-4af9-c492-14673410a05c"
      },
      "id": "Mvy5-0Bxi_Uw",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f7293b67",
      "metadata": {
        "id": "f7293b67"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aqDUtXmi85l",
        "outputId": "d0cc3784-9cca-4032-c16d-44fd24ecbf45"
      },
      "id": "0aqDUtXmi85l",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=4b498614cac075c0314c581644f89a50391177ff49930ca6e0d28ef45b2c9305\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9c9c0dfc",
      "metadata": {
        "id": "9c9c0dfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import SparsePCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC,NuSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn import under_sampling, over_sampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import Perceptron\n",
        "from scipy.sparse import random\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b96e4458",
      "metadata": {
        "id": "b96e4458"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c4bbdcde",
      "metadata": {
        "id": "c4bbdcde"
      },
      "outputs": [],
      "source": [
        "train_file = '/content/gdrive/MyDrive/trainfile.txt'\n",
        "test_file = '/content/gdrive/MyDrive/testfile.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8bb63900",
      "metadata": {
        "id": "8bb63900"
      },
      "outputs": [],
      "source": [
        "feature_size = 100001\n",
        "k_folds = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "74823287",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "74823287"
      },
      "outputs": [],
      "source": [
        "print_debug = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a1e1dcab",
      "metadata": {
        "id": "a1e1dcab"
      },
      "outputs": [],
      "source": [
        "def load(filename, ftype):\n",
        "    with open(filename, \"r\") as rf1:\n",
        "        lines = rf1.readlines()\n",
        "\n",
        "    if ftype == \"train\":\n",
        "        labels = [int(l[0]) for l in lines]\n",
        "        for index, item in enumerate(labels):\n",
        "            if (item == 0):\n",
        "                labels[index] = -1\n",
        "        docs = [re.sub(r'[^\\w]', ' ',l[1:]).split() for l in lines]\n",
        "\n",
        "    else:\n",
        "        labels = []\n",
        "        docs = [re.sub(r'[^\\w]', ' ',l).split() for l in lines]\n",
        "\n",
        "    features = []\n",
        "\n",
        "    for doc in docs:\n",
        "        line = [0]*feature_size\n",
        "        for index, val in enumerate(doc):\n",
        "            line[int(val)] = 1\n",
        "        features.append(line)\n",
        "\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a2d1987f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2d1987f",
        "outputId": "e0a98231-541f-405e-c80f-84c66e20c36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting processing for drug activity prediction\n"
          ]
        }
      ],
      "source": [
        "print ('Starting processing for drug activity prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1e992ee6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e992ee6",
        "outputId": "9886d30b-c12e-485b-adcf-ffe70257d534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data\n"
          ]
        }
      ],
      "source": [
        "print (\"Loading training data\")\n",
        "# Loading train.dat file\n",
        "features, labels = load(train_file, \"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f95c1266",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f95c1266",
        "outputId": "1817d5a2-6b1a-4038-900d-cd9fe2c5b269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reducing Dimensions using Truncated SVD on train data\n"
          ]
        }
      ],
      "source": [
        "#Using Dimensionality Reduction on train data\n",
        "print (\"Reducing Dimensions using Truncated SVD on train data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b044b3b5",
      "metadata": {
        "id": "b044b3b5"
      },
      "outputs": [],
      "source": [
        "svd_trunc = TruncatedSVD(algorithm='randomized', n_components=1500, n_iter=50, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3dbfb3d5",
      "metadata": {
        "id": "3dbfb3d5"
      },
      "outputs": [],
      "source": [
        "svd_trunc_m = svd_trunc.fit(features, labels)\n",
        "rd_feature = svd_trunc_m.transform(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad626b16",
      "metadata": {
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad626b16",
        "outputId": "ecf576f2-e661-480d-d046-01a415a90998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oversampling data using SMOTE!\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "reduced_features,labels = oversample.fit_resample(reduced_features, labels)\n",
        "print (\"Oversampling data using SMOTE!\")\n",
        "sm = SMOTE(random_state=42)\n",
        "rd_features, labels = sm.fit_resample(reduced_features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d60f5b1e",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "d60f5b1e"
      },
      "outputs": [],
      "source": [
        "test_features, test_labels = load(test_file, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a423d4a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a423d4a",
        "outputId": "0d645549-6612-46e2-b261-4648f2235fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reducing Dimensions using Truncated SVD on test data\n"
          ]
        }
      ],
      "source": [
        "print (\"Reducing Dimensions using Truncated SVD on test data\")\n",
        "test_rd_features = svd_trunc_m.transform(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_rd_features.shape)\n",
        "print(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J0Ebod0S-lX",
        "outputId": "08eb58ff-f7ae-4689-d8da-d0f115855f93"
      },
      "id": "_J0Ebod0S-lX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(350, 800)\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e97cad",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "63e97cad"
      },
      "outputs": [],
      "source": [
        "# Classifying\n",
        "names = [\"Decision Tree classifier\"]\n",
        "classifiers = [DecisionTreeClassifier(random_state=53,class_weight={-1: 1, 1: 1.5})]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_error(y, y_pred, w_i):\n",
        "    \n",
        "    return (sum(w_i * (np.not_equal(y, y_pred)).astype(int)))/sum(w_i)\n",
        "\n",
        "def compute_alpha(error):\n",
        "   \n",
        "    return np.log((1 - error) / error)\n",
        "\n",
        "def update_weights(w_i, alpha, y, y_pred):\n",
        "    \n",
        "    return w_i * np.exp(alpha * (np.not_equal(y, y_pred)).astype(int))"
      ],
      "metadata": {
        "id": "kpuv7X7cUph5"
      },
      "id": "kpuv7X7cUph5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaBoost:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.alphas = []\n",
        "        self.G_M = []\n",
        "        self.M = None\n",
        "        self.train_errors = []\n",
        "        self.pred_errors = []\n",
        "\n",
        "    def fit(self, X, y, Z = 100):\n",
        "        \n",
        "        \n",
        "    \n",
        "        self.alphas = [] \n",
        "        self.train_errors = []\n",
        "        self.Z = Z\n",
        "\n",
        "      \n",
        "        for z in range(0, M):\n",
        "            \n",
        "            \n",
        "            if z == 0:\n",
        "                w_i = np.ones(len(y)) * 1 / len(y)  \n",
        "            else:\n",
        "             \n",
        "                w_i = update_weights(w_i, alpha_m, y, y_pred)\n",
        "            \n",
        "            \n",
        "            G_m = DecisionTreeClassifier(max_depth = 1)   \n",
        "            G_m.fit(X, y, sample_weight = w_i)\n",
        "            y_pred = G_m.predict(X)\n",
        "            \n",
        "            self.G_M.append(G_z) \n",
        "\n",
        "            \n",
        "            error_m = compute_error(y, y_pred, w_i)\n",
        "            self.training_errors.append(error_z)\n",
        "\n",
        "           \n",
        "            alpha_m = compute_alpha(error_z)\n",
        "            self.alphas.append(alpha_z)\n",
        "\n",
        "        assert len(self.G_z) == len(self.alphas)"
      ],
      "metadata": {
        "id": "1lprkw6um16_"
      },
      "id": "1lprkw6um16_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in zip(names, classifiers):\n",
        "    print ('Report on ' + name)\n",
        "    cv_predicted = cross_val_predict(clf, reduced_features, labels, cv=k_folds)\n",
        "\n",
        "    print (metrics.classification_report(labels, cv_predicted))\n",
        "\n",
        "    scores = cross_val_score(clf, reduced_features, labels)\n",
        "\n",
        "    print ('\\nCross validation scores: ')\n",
        "    print (scores.mean())\n",
        "\n",
        "    #training classifier\n",
        "    clf.fit(reduced_features, labels)\n",
        "\n",
        "    # Predict test labels\n",
        "    test_predicted = clf.predict(test_rd_features)\n",
        "\n",
        "    print ('Test predicted for ' + name)\n",
        "\n",
        "    result_file = 'format.txt'\n",
        "\n",
        "    print ('Output stored in', result_file)\n",
        "\n",
        "    output = open(result_file, 'w')\n",
        "    for t in test_predicted:\n",
        "        if int(t) == -1:\n",
        "            t = 0\n",
        "        output.write(str(t))\n",
        "        output.write(\"\\n\")\n",
        "    output.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rcoSXejvqIS",
        "outputId": "556ed029-caf0-4ac0-d6f2-4f0bb60b4f57"
      },
      "id": "_rcoSXejvqIS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report on KNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00       722\n",
            "           1       0.50      1.00      0.67       722\n",
            "\n",
            "    accuracy                           0.50      1444\n",
            "   macro avg       0.25      0.50      0.33      1444\n",
            "weighted avg       0.25      0.50      0.33      1444\n",
            "\n",
            "\n",
            "Cross validation scores: \n",
            "0.5\n",
            "Test predicted for KNN\n",
            "Output stored in format.txt\n",
            "Report on Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.95      0.89      0.92       722\n",
            "           1       0.89      0.95      0.92       722\n",
            "\n",
            "    accuracy                           0.92      1444\n",
            "   macro avg       0.92      0.92      0.92      1444\n",
            "weighted avg       0.92      0.92      0.92      1444\n",
            "\n",
            "\n",
            "Cross validation scores: \n",
            "0.9099889465590157\n",
            "Test predicted for Decision Tree\n",
            "Output stored in format.txt\n",
            "Report on SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.99      1.00       722\n",
            "           1       0.99      1.00      1.00       722\n",
            "\n",
            "    accuracy                           1.00      1444\n",
            "   macro avg       1.00      1.00      1.00      1444\n",
            "weighted avg       1.00      1.00      1.00      1444\n",
            "\n",
            "\n",
            "Cross validation scores: \n",
            "0.995847750865052\n",
            "Test predicted for SVM\n",
            "Output stored in format.txt\n",
            "Report on Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.83      0.99      0.90       722\n",
            "           1       0.99      0.80      0.88       722\n",
            "\n",
            "    accuracy                           0.89      1444\n",
            "   macro avg       0.91      0.89      0.89      1444\n",
            "weighted avg       0.91      0.89      0.89      1444\n",
            "\n",
            "\n",
            "Cross validation scores: \n",
            "0.8947808535178778\n",
            "Test predicted for Naive Bayes\n",
            "Output stored in format.txt\n",
            "Report on LogisticRegression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.99      1.00       722\n",
            "           1       0.99      1.00      1.00       722\n",
            "\n",
            "    accuracy                           1.00      1444\n",
            "   macro avg       1.00      1.00      1.00      1444\n",
            "weighted avg       1.00      1.00      1.00      1444\n",
            "\n",
            "\n",
            "Cross validation scores: \n",
            "0.995847750865052\n",
            "Test predicted for LogisticRegression\n",
            "Output stored in format.txt\n",
            "Report on AdaBoost\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      0.97      0.98       722\n",
            "           1       0.97      0.99      0.98       722\n",
            "\n",
            "    accuracy                           0.98      1444\n",
            "   macro avg       0.98      0.98      0.98      1444\n",
            "weighted avg       0.98      0.98      0.98      1444\n",
            "\n",
            "\n",
            "Cross validation scores: \n",
            "0.9750696847366397\n",
            "Test predicted for AdaBoost\n",
            "Output stored in format.txt\n",
            "Report on RandomForest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.98      0.99      0.98       722\n",
            "           1       0.99      0.98      0.98       722\n",
            "\n",
            "    accuracy                           0.98      1444\n",
            "   macro avg       0.98      0.98      0.98      1444\n",
            "weighted avg       0.98      0.98      0.98      1444\n",
            "\n",
            "\n",
            "Cross validation scores: \n",
            "0.969535755478662\n",
            "Test predicted for RandomForest\n",
            "Output stored in format.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for "
      ],
      "metadata": {
        "id": "M2_EV06Q1G-f"
      },
      "id": "M2_EV06Q1G-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lGOI2_6vvqoT"
      },
      "id": "lGOI2_6vvqoT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}